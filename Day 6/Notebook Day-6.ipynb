{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47cf6f7e-8d8f-46d0-a0a3-f96e2f41c691",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "BRONZE Volume: Raw ingestion path"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "df_bronze = spark.read.option(\"header\", True).option(\"inferschema\",True).csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv\")\n",
    "df_bronze.withColumn(\"ingesttime\", current_timestamp()) \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\").save(\"/Volumes/workspace/ecommerce/bronze/ecommerce_data_2019_oct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54820f83-869c-4d2e-aa80-cee9913d33f3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "BRONZE Table: Raw ingestion"
    }
   },
   "outputs": [],
   "source": [
    "df_bronze = spark.read.option(\"header\", True).option(\"inferschema\",True).csv(\"/Volumes/workspace/ecommerce/ecommerce_data/2019-Oct.csv\")\n",
    "df_bronze.withColumn(\"ingesttime\", current_timestamp()) \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.bronze.ecommerce_data_2019_oct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8531029-5af5-41c1-827f-ea201730dc5e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Silver Table: cleaning & validation"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim\n",
    "\n",
    "# Read from bronze table\n",
    "df_bronze = spark.read.table(\"workspace.bronze.ecommerce_data_2019_oct\")\n",
    "\n",
    "# Data cleaning and validation\n",
    "df_silver = (\n",
    "    df_bronze\n",
    "    .dropDuplicates()\n",
    "    .filter(col(\"price\").isNotNull() & (col(\"price\") > 0))\n",
    "    .withColumn(\"product_id\", trim(col(\"product_id\")))\n",
    "    .withColumn(\"user_id\", trim(col(\"user_id\")))\n",
    ")\n",
    "\n",
    "# Save to silver layer\n",
    "df_silver.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.silver.ecommerce_data_2019_oct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71f8cfd4-c8ed-4608-b521-fdd7a72cb767",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Gold Table: business aggregates"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Read from silver table\n",
    "df_silver = spark.read.table(\"workspace.silver.ecommerce_data_2019_oct\")\n",
    "\n",
    "# Data aggregations\n",
    "df_gold = df_silver.groupBy(\"product_id\", \"category_id\") \\\n",
    "    .agg(\n",
    "        F.countDistinct(F.when(F.col(\"event_type\")==\"view\", \"user_id\")).alias(\"views\"),\n",
    "        F.countDistinct(F.when(F.col(\"event_type\")==\"purchase\", \"user_id\")).alias(\"purchases\"),\n",
    "        F.sum(F.when(F.col(\"event_type\")==\"purchase\", F.col(\"price\"))).alias(\"revenue\")\n",
    "    )\n",
    "\n",
    "# Fix: Avoid division by zero\n",
    "conversion_rate_expr = F.when(F.col(\"views\") > 0, F.col(\"purchases\")/F.col(\"views\")*100)\n",
    "df_gold = df_gold.withColumn(\"conversion_rate\", conversion_rate_expr)\n",
    "\n",
    "# save to gold layer\n",
    "df_gold.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"workspace.gold.products\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Notebook Day-6",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}